Hyperparameters are external parameters are set 

Examples
**Learning Rate**
**Epochs**
**Batch Size**


**Learning Rate** - Determines the size of the step taken during gradient descent optimizationn.

Between 0 and 1


**Batch Size** - The number of Samples used to train at any one time
                  Could be all, one,  or some of your data (batch, stochastic or mini-batdh)
                  OFten 32, 64 and 128
                  Calculable from infrastructure



**Epochs** -  The number of times that the algorithm will process the entire training data

              Each epoch contains one or more batches
              Each epoch should see the model get closer to the desired state
              Usually a high number: 10, 100,1000 and up